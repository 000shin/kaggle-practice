{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pubg",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "2G46wEwhMcNS",
        "outputId": "72b6d77a-58cb-4b2a-828f-e8cd58d093e5",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c pubg-finish-placement-prediction\n",
        "!unzip train_V2.csv.zip\n",
        "!unzip test_V2.csv.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0dc5d5d3-fd5c-4f4c-b4b0-4583ddf06c32\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0dc5d5d3-fd5c-4f4c-b4b0-4583ddf06c32\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading sample_submission_V2.csv.zip to /content\n",
            " 53% 9.00M/16.9M [00:00<00:00, 11.7MB/s]\n",
            "100% 16.9M/16.9M [00:00<00:00, 23.1MB/s]\n",
            "Downloading test_V2.csv.zip to /content\n",
            " 99% 97.0M/98.3M [00:02<00:00, 34.1MB/s]\n",
            "100% 98.3M/98.3M [00:02<00:00, 39.3MB/s]\n",
            "Downloading train_V2.csv.zip to /content\n",
            " 97% 233M/239M [00:06<00:00, 46.6MB/s]\n",
            "100% 239M/239M [00:06<00:00, 38.4MB/s]\n",
            "Archive:  train_V2.csv.zip\n",
            "  inflating: train_V2.csv            \n",
            "Archive:  test_V2.csv.zip\n",
            "  inflating: test_V2.csv             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-KjiiDskL9RG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "import warnings\n",
        "import gc\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import lightgbm as lgb\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "id_VSpGq7kuF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kc6HjrvCMnvo",
        "colab_type": "code",
        "outputId": "d0b0ea78-52e7-45c4-bb6b-67ef8a0e62d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_V2.csv')\n",
        "train = train[train['maxPlace']>1]\n",
        "train = train[train['winPlacePerc'].notnull()]\n",
        "test = pd.read_csv('test_V2.csv')\n",
        "train = reduce_mem_usage(train)\n",
        "test = reduce_mem_usage(test)\n",
        "print(train.shape, test.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1017.83 MB\n",
            "Memory usage after optimization is: 322.31 MB\n",
            "Decreased by 68.3%\n",
            "Memory usage of dataframe is 413.18 MB\n",
            "Memory usage after optimization is: 121.74 MB\n",
            "Decreased by 70.5%\n",
            "(4446965, 29) (1934174, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_b6uJWfrNBSj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alldata = [train, test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2hcqhkeQjcR5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Feature Engineering"
      ]
    },
    {
      "metadata": {
        "id": "vClOOwU-i98g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for data in alldata :\n",
        "  data['playersJoined'] = data.groupby('matchId')['matchId'].transform('count')\n",
        "  data['healsAndBoosts'] = data['heals']+data['boosts']\n",
        "  data['totalDistance'] = data['walkDistance']+ 0.25* data['rideDistance'] + data['swimDistance']\n",
        "  data['distancePerDuration'] = data['totalDistance'] / data['matchDuration']\n",
        "  data['killsPerDistance'] = data['kills']/(data['totalDistance']+1) \n",
        "  data['killsPerDistance'].fillna(0, inplace=True)\n",
        "  data['headshotKillRate'] = data['headshotKills'] / data['kills']\n",
        "  data['killStreakRate'] = data['killStreaks']/data['kills']\n",
        "  data['weaponsPerDistance'] =data['weaponsAcquired']/(data['totalDistance']+1)\n",
        "  data['weaponsPerDistance'].fillna(0, inplace=True)\n",
        "  data['skill'] = data['headshotKills'] + data['roadKills'] + data['vehicleDestroys']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYugJ4fxCoNF",
        "colab_type": "code",
        "outputId": "f241454d-3f73-4c44-a9ae-336ea8773389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "for data in alldata:\n",
        "  data['matchType'] = data['matchType'].map({\n",
        "      'crashfpp':1,\n",
        "      'crashtpp':2,\n",
        "      'duo':3,\n",
        "      'duo-fpp':4,\n",
        "      'flarefpp':5,\n",
        "      'flaretpp':6,\n",
        "      'normal-duo':7,\n",
        "      'normal-duo-fpp':8,\n",
        "      'normal-solo':9,\n",
        "      'normal-solo-fpp':10,\n",
        "      'normal-squad':11,\n",
        "      'normal-squad-fpp':12,\n",
        "      'solo':13,\n",
        "      'solo-fpp':14,\n",
        "      'squad':15,\n",
        "      'squad-fpp':16\n",
        "  })\n",
        "  data = reduce_mem_usage(data)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 483.47 MB\n",
            "Memory usage after optimization is: 356.24 MB\n",
            "Decreased by 26.3%\n",
            "Memory usage of dataframe is 191.84 MB\n",
            "Memory usage after optimization is: 136.50 MB\n",
            "Decreased by 28.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HPWS0JJMC3-D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for data in alldata:\n",
        "  data.loc[(data['rankPoints']==-1), 'rankPoints'] = 0\n",
        "  data['points'] = data['rankPoints']+data['killPoints']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFrs0O6bBNUd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for data in alldata:\n",
        "  match = data.groupby('matchId')\n",
        "  data['killsPerc'] = match['kills'].rank(pct=True).values\n",
        "  data['killPlacePerc'] = match['killPlace'].rank(pct=True).values\n",
        "  data['walkDistancePerc'] = match['walkDistance'].rank(pct=True).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rPy2P7qLyPbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0199016-f566-4e7f-e5ae-a36934c770a7"
      },
      "cell_type": "code",
      "source": [
        "for data in alldata:\n",
        "  data[data==np.Inf] = np.NaN\n",
        "  data[data==np.NINF] = np.NaN\n",
        "  data.fillna(0, inplace=True)\n",
        "  \n",
        "print(train.shape, test.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4446965, 42) (1934174, 41)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lRAwlG47BORc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Group & Match"
      ]
    },
    {
      "metadata": {
        "id": "e6Cy2QKcDHGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = list(train.columns)\n",
        "excl_col = ['Id','matchId','groupId','playersJoined','matchType','winPlacePerc']\n",
        "for c in excl_col:\n",
        "    features.remove(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CAdlC1hZB1Hi",
        "colab_type": "code",
        "outputId": "7ec3228e-4c38-4ad4-aabf-d158dc287681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "def meandata(data):\n",
        "  meanData = data.groupby(['matchId','groupId'])[features].agg('mean')\n",
        "  meanData = reduce_mem_usage(meanData)\n",
        "  meanData = meanData.replace([np.inf, np.NINF,np.nan], 0)\n",
        "  meanDataRank = meanData.groupby('matchId')[features].rank(pct=True).reset_index()\n",
        "  meanDataRank = reduce_mem_usage(meanDataRank)\n",
        "  data = pd.merge(data, meanData.reset_index(), suffixes=[\"\", \"_mean\"], how='left', on=['matchId', 'groupId'])\n",
        "  del meanData\n",
        "  gc.collect()\n",
        "  data.drop([\"vehicleDestroys_mean\",\"rideDistance_mean\",\"roadKills_mean\",\"rankPoints_mean\"], axis=1, inplace=True)\n",
        "  data = pd.merge(data, meanDataRank, suffixes=[\"\", \"_meanRank\"], how='left', on=['matchId', 'groupId'])\n",
        "  del meanDataRank\n",
        "  gc.collect()\n",
        "  data.drop([\"numGroups_meanRank\",\"rankPoints_meanRank\"], axis=1, inplace=True)\n",
        "  data = reduce_mem_usage(data)\n",
        "  return data\n",
        "\n",
        "train = meandata(train)\n",
        "test = meandata(test)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 460.39 MB\n",
            "Memory usage after optimization is: 170.46 MB\n",
            "Decreased by 63.0%\n",
            "Memory usage of dataframe is 587.59 MB\n",
            "Memory usage after optimization is: 170.09 MB\n",
            "Decreased by 71.1%\n",
            "Memory usage of dataframe is 1026.31 MB\n",
            "Memory usage after optimization is: 949.97 MB\n",
            "Decreased by 7.4%\n",
            "Memory usage of dataframe is 199.62 MB\n",
            "Memory usage after optimization is: 72.84 MB\n",
            "Decreased by 63.5%\n",
            "Memory usage of dataframe is 256.94 MB\n",
            "Memory usage after optimization is: 74.38 MB\n",
            "Decreased by 71.1%\n",
            "Memory usage of dataframe is 442.70 MB\n",
            "Memory usage after optimization is: 409.49 MB\n",
            "Decreased by 7.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HcR2R1uCEtNw",
        "colab_type": "code",
        "outputId": "be595b65-32a0-4295-9413-ac41ba1dd32a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "def groupsize(data):\n",
        "  groupSize = data.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n",
        "  groupSize = reduce_mem_usage(groupSize)\n",
        "  data = pd.merge(data, groupSize, how='left', on=['matchId', 'groupId'])\n",
        "  del groupSize\n",
        "  gc.collect()\n",
        "  return data\n",
        "\n",
        "train = groupsize(train)\n",
        "test = groupsize(test)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 46.39 MB\n",
            "Memory usage after optimization is: 32.86 MB\n",
            "Decreased by 29.2%\n",
            "Memory usage of dataframe is 20.28 MB\n",
            "Memory usage after optimization is: 14.37 MB\n",
            "Decreased by 29.2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XHd4z7N55DyZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "matchMeanFeatures = list(test.columns)[:41]\n",
        "excl_col = ['killPlacePerc','matchDuration','maxPlace','numGroups']\n",
        "for c in excl_col:\n",
        "  matchMeanFeatures.remove(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "URzx74g1EtWK",
        "colab_type": "code",
        "outputId": "8a14b105-42cd-4978-b275-ab6d8c5083c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "def matchdata(data):\n",
        "  meanData = data.groupby(['matchId'])[matchMeanFeatures].agg('mean')\n",
        "  meanData = reduce_mem_usage(meanData)\n",
        "  meanData = meanData.replace([np.inf, np.NINF,np.nan], 0)\n",
        "  data = pd.merge(data, meanData.reset_index(), suffixes=[\"\", \"_matchMean\"], how='left', on=['matchId'])\n",
        "  del meanData\n",
        "  gc.collect()\n",
        "  return data\n",
        "\n",
        "train = matchdata(train)\n",
        "test = matchdata(test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 9.24 MB\n",
            "Memory usage after optimization is: 3.48 MB\n",
            "Decreased by 62.4%\n",
            "Memory usage of dataframe is 3.96 MB\n",
            "Memory usage after optimization is: 1.49 MB\n",
            "Decreased by 62.4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VRtQVvA9wgHU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#dropping features\n",
        "train.drop(['boosts','heals', 'headshotKills','roadKills','vehicleDestroys','killStreaks','rideDistance','swimDistance','matchDuration', 'maxPlace','numGroups','Id','groupId'], axis=1, inplace=True)\n",
        "test.drop(['boosts','heals', 'headshotKills','roadKills','vehicleDestroys','killStreaks','rideDistance','swimDistance','matchDuration', 'maxPlace','numGroups','Id','groupId'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XihWhY761MJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "146459ba-5f7e-4fe7-d447-d3b06b74e4c7"
      },
      "cell_type": "code",
      "source": [
        "print(train.shape, test.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4446965, 130) (1934174, 129)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wXJ4GANUw5Qn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_features = test.columns\n",
        "final_features = final_features.drop('matchId')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gy3iPyOkOHwX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train & Predict"
      ]
    },
    {
      "metadata": {
        "id": "-C71USRinadN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_train_val(data, fraction):\n",
        "    matchIds = data['matchId'].unique().reshape([-1])\n",
        "    train_size = int(len(matchIds)*fraction)\n",
        "    \n",
        "    random_idx = np.random.RandomState(seed=2).permutation(len(matchIds))\n",
        "    train_matchIds = matchIds[random_idx[:train_size]]\n",
        "    val_matchIds = matchIds[random_idx[train_size:]]\n",
        "    \n",
        "    data_train = data.loc[data['matchId'].isin(train_matchIds)]\n",
        "    data_val = data.loc[data['matchId'].isin(val_matchIds)]\n",
        "    return data_train, data_val\n",
        "  \n",
        "X_train, X_val = split_train_val(train, 0.91)\n",
        "del train\n",
        "gc.collect()\n",
        "y_train = X_train['winPlacePerc']\n",
        "X_train = X_train.drop(columns=['matchId', 'winPlacePerc'])\n",
        "y_val = X_val['winPlacePerc']\n",
        "X_val = X_val.drop(columns=['matchId', 'winPlacePerc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xRAJLm3KoM0B",
        "colab_type": "code",
        "outputId": "0bb9786d-9d2e-4293-8617-89a6433dc51c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "#Split the Data again and then join it. I am doing this because If I turn the Pandas DataFrame into Numpy Array with \n",
        "# all rows at once, Kernel will be killed for exceeding 16GB Memory. \n",
        "X_train, X_train2, y_train, y_train2 = train_test_split(X_train, y_train, test_size=0.1, shuffle=False)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_train2 = np.array(X_train2)\n",
        "y_train2 = np.array(y_train2)\n",
        "y_train = np.concatenate((y_train, y_train2), axis=0)\n",
        "del y_train2\n",
        "gc.collect()\n",
        "X_train = np.concatenate((X_train, X_train2), axis=0)\n",
        "del X_train2\n",
        "gc.collect()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "bVpTsfxyomik",
        "colab_type": "code",
        "outputId": "889d2210-f138-485a-80cf-217db7864dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_set = lgb.Dataset(X_train, label=y_train)\n",
        "del X_train,y_train\n",
        "gc.collect()\n",
        "valid_set = lgb.Dataset(X_val, label=y_val)\n",
        "del X_val, y_val\n",
        "gc.collect()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "_tmpNU7UoxAG",
        "colab_type": "code",
        "outputId": "8a4e193c-c3fb-4e4f-a6db-5da8e15b1b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1615
        }
      },
      "cell_type": "code",
      "source": [
        "params = {\n",
        "        \"objective\" : \"regression\", \n",
        "        \"metric\" : \"mae\", \n",
        "        \"num_leaves\" : 149, \n",
        "        \"learning_rate\" : 0.03, \n",
        "        \"bagging_fraction\" : 0.9,\n",
        "        \"bagging_seed\" : 0, \n",
        "        \"num_threads\" : 4,\n",
        "        \"colsample_bytree\" : 0.5,\n",
        "        'min_data_in_leaf':1900, \n",
        "        'min_split_gain':0.00011,\n",
        "        'lambda_l2':9\n",
        "}\n",
        "\n",
        "model = lgb.train(  params, \n",
        "                    train_set = train_set,\n",
        "                    num_boost_round=9000,\n",
        "                    early_stopping_rounds=200,\n",
        "                    verbose_eval=100, \n",
        "                    valid_sets=[train_set,valid_set]\n",
        "                  )\n",
        "  \n",
        "del train_set,valid_set\n",
        "gc.collect()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 200 rounds.\n",
            "[100]\ttraining's l1: 0.0428769\tvalid_1's l1: 0.0427829\n",
            "[200]\ttraining's l1: 0.0348968\tvalid_1's l1: 0.034997\n",
            "[300]\ttraining's l1: 0.0332657\tvalid_1's l1: 0.0335061\n",
            "[400]\ttraining's l1: 0.0321958\tvalid_1's l1: 0.0325481\n",
            "[500]\ttraining's l1: 0.0314616\tvalid_1's l1: 0.0319104\n",
            "[600]\ttraining's l1: 0.0308841\tvalid_1's l1: 0.0314321\n",
            "[700]\ttraining's l1: 0.0304251\tvalid_1's l1: 0.0310735\n",
            "[800]\ttraining's l1: 0.030031\tvalid_1's l1: 0.0307827\n",
            "[900]\ttraining's l1: 0.029702\tvalid_1's l1: 0.0305571\n",
            "[1000]\ttraining's l1: 0.0294084\tvalid_1's l1: 0.0303672\n",
            "[1100]\ttraining's l1: 0.0291466\tvalid_1's l1: 0.0301971\n",
            "[1200]\ttraining's l1: 0.0289103\tvalid_1's l1: 0.0300548\n",
            "[1300]\ttraining's l1: 0.028695\tvalid_1's l1: 0.0299334\n",
            "[1400]\ttraining's l1: 0.0284932\tvalid_1's l1: 0.029827\n",
            "[1500]\ttraining's l1: 0.0283092\tvalid_1's l1: 0.0297336\n",
            "[1600]\ttraining's l1: 0.0281407\tvalid_1's l1: 0.0296583\n",
            "[1700]\ttraining's l1: 0.0279822\tvalid_1's l1: 0.0295901\n",
            "[1800]\ttraining's l1: 0.0278309\tvalid_1's l1: 0.0295303\n",
            "[1900]\ttraining's l1: 0.0276854\tvalid_1's l1: 0.0294729\n",
            "[2000]\ttraining's l1: 0.0275484\tvalid_1's l1: 0.0294223\n",
            "[2100]\ttraining's l1: 0.0274184\tvalid_1's l1: 0.0293802\n",
            "[2200]\ttraining's l1: 0.0272918\tvalid_1's l1: 0.029338\n",
            "[2300]\ttraining's l1: 0.027173\tvalid_1's l1: 0.0293039\n",
            "[2400]\ttraining's l1: 0.0270513\tvalid_1's l1: 0.0292689\n",
            "[2500]\ttraining's l1: 0.0269353\tvalid_1's l1: 0.0292386\n",
            "[2600]\ttraining's l1: 0.0268258\tvalid_1's l1: 0.0292107\n",
            "[2700]\ttraining's l1: 0.0267227\tvalid_1's l1: 0.0291822\n",
            "[2800]\ttraining's l1: 0.0266207\tvalid_1's l1: 0.0291547\n",
            "[2900]\ttraining's l1: 0.0265162\tvalid_1's l1: 0.0291305\n",
            "[3000]\ttraining's l1: 0.0264131\tvalid_1's l1: 0.0291096\n",
            "[3100]\ttraining's l1: 0.0263136\tvalid_1's l1: 0.0290865\n",
            "[3200]\ttraining's l1: 0.0262151\tvalid_1's l1: 0.0290656\n",
            "[3300]\ttraining's l1: 0.0261202\tvalid_1's l1: 0.0290478\n",
            "[3400]\ttraining's l1: 0.0260291\tvalid_1's l1: 0.0290313\n",
            "[3500]\ttraining's l1: 0.0259367\tvalid_1's l1: 0.0290134\n",
            "[3600]\ttraining's l1: 0.0258475\tvalid_1's l1: 0.0289988\n",
            "[3700]\ttraining's l1: 0.0257555\tvalid_1's l1: 0.0289828\n",
            "[3800]\ttraining's l1: 0.025667\tvalid_1's l1: 0.0289663\n",
            "[3900]\ttraining's l1: 0.0255821\tvalid_1's l1: 0.0289542\n",
            "[4000]\ttraining's l1: 0.0254971\tvalid_1's l1: 0.0289403\n",
            "[4100]\ttraining's l1: 0.0254154\tvalid_1's l1: 0.028929\n",
            "[4200]\ttraining's l1: 0.0253355\tvalid_1's l1: 0.0289169\n",
            "[4300]\ttraining's l1: 0.0252572\tvalid_1's l1: 0.0289032\n",
            "[4400]\ttraining's l1: 0.0251767\tvalid_1's l1: 0.0288914\n",
            "[4500]\ttraining's l1: 0.0250991\tvalid_1's l1: 0.0288791\n",
            "[4600]\ttraining's l1: 0.0250209\tvalid_1's l1: 0.0288687\n",
            "[4700]\ttraining's l1: 0.0249445\tvalid_1's l1: 0.0288577\n",
            "[4800]\ttraining's l1: 0.0248676\tvalid_1's l1: 0.0288444\n",
            "[4900]\ttraining's l1: 0.0247934\tvalid_1's l1: 0.0288353\n",
            "[5000]\ttraining's l1: 0.024719\tvalid_1's l1: 0.0288254\n",
            "[5100]\ttraining's l1: 0.0246461\tvalid_1's l1: 0.0288165\n",
            "[5200]\ttraining's l1: 0.0245735\tvalid_1's l1: 0.0288086\n",
            "[5300]\ttraining's l1: 0.0245007\tvalid_1's l1: 0.0288022\n",
            "[5400]\ttraining's l1: 0.0244309\tvalid_1's l1: 0.0287933\n",
            "[5500]\ttraining's l1: 0.0243608\tvalid_1's l1: 0.0287854\n",
            "[5600]\ttraining's l1: 0.0242923\tvalid_1's l1: 0.0287778\n",
            "[5700]\ttraining's l1: 0.0242245\tvalid_1's l1: 0.0287704\n",
            "[5800]\ttraining's l1: 0.024158\tvalid_1's l1: 0.0287648\n",
            "[5900]\ttraining's l1: 0.0240921\tvalid_1's l1: 0.0287568\n",
            "[6000]\ttraining's l1: 0.0240258\tvalid_1's l1: 0.0287496\n",
            "[6100]\ttraining's l1: 0.0239596\tvalid_1's l1: 0.0287418\n",
            "[6200]\ttraining's l1: 0.0238952\tvalid_1's l1: 0.0287357\n",
            "[6300]\ttraining's l1: 0.0238287\tvalid_1's l1: 0.0287322\n",
            "[6400]\ttraining's l1: 0.0237665\tvalid_1's l1: 0.0287276\n",
            "[6500]\ttraining's l1: 0.0237025\tvalid_1's l1: 0.028724\n",
            "[6600]\ttraining's l1: 0.0236399\tvalid_1's l1: 0.0287192\n",
            "[6700]\ttraining's l1: 0.0235788\tvalid_1's l1: 0.0287136\n",
            "[6800]\ttraining's l1: 0.023519\tvalid_1's l1: 0.0287071\n",
            "[6900]\ttraining's l1: 0.0234576\tvalid_1's l1: 0.0287037\n",
            "[7000]\ttraining's l1: 0.0233949\tvalid_1's l1: 0.0286975\n",
            "[7100]\ttraining's l1: 0.0233364\tvalid_1's l1: 0.0286925\n",
            "[7200]\ttraining's l1: 0.0232773\tvalid_1's l1: 0.0286874\n",
            "[7300]\ttraining's l1: 0.0232184\tvalid_1's l1: 0.0286832\n",
            "[7400]\ttraining's l1: 0.0231607\tvalid_1's l1: 0.02868\n",
            "[7500]\ttraining's l1: 0.0231014\tvalid_1's l1: 0.028676\n",
            "[7600]\ttraining's l1: 0.0230444\tvalid_1's l1: 0.0286712\n",
            "[7700]\ttraining's l1: 0.0229871\tvalid_1's l1: 0.0286669\n",
            "[7800]\ttraining's l1: 0.0229302\tvalid_1's l1: 0.0286612\n",
            "[7900]\ttraining's l1: 0.0228726\tvalid_1's l1: 0.0286587\n",
            "[8000]\ttraining's l1: 0.0228187\tvalid_1's l1: 0.0286549\n",
            "[8100]\ttraining's l1: 0.0227652\tvalid_1's l1: 0.02865\n",
            "[8200]\ttraining's l1: 0.0227097\tvalid_1's l1: 0.0286476\n",
            "[8300]\ttraining's l1: 0.0226577\tvalid_1's l1: 0.0286434\n",
            "[8400]\ttraining's l1: 0.0226005\tvalid_1's l1: 0.0286399\n",
            "[8500]\ttraining's l1: 0.0225452\tvalid_1's l1: 0.0286382\n",
            "[8600]\ttraining's l1: 0.0224921\tvalid_1's l1: 0.0286355\n",
            "[8700]\ttraining's l1: 0.0224379\tvalid_1's l1: 0.0286318\n",
            "[8800]\ttraining's l1: 0.0223851\tvalid_1's l1: 0.0286295\n",
            "[8900]\ttraining's l1: 0.0223332\tvalid_1's l1: 0.0286268\n",
            "[9000]\ttraining's l1: 0.022281\tvalid_1's l1: 0.0286239\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[9000]\ttraining's l1: 0.022281\tvalid_1's l1: 0.0286239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "fD_92bVZe9Fj",
        "colab_type": "code",
        "outputId": "1e9d34ce-6102-4931-fc4f-47f7cc18661a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "featureImp = list(model.feature_importance())\n",
        "featureImp, features_label = zip(*sorted(zip(featureImp, final_features)))\n",
        "with open(\"FeatureImportance.txt\", \"w\") as text_file:\n",
        "    for i in range(len(featureImp)):\n",
        "        print(f\"{final_features[i]} =  {featureImp[i]}\", file=text_file)\n",
        "del featureImp,final_features\n",
        "gc.collect()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "koNVGDFJA9HW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1d9018f-933e-4297-b13e-375b92297fa5"
      },
      "cell_type": "code",
      "source": [
        "X_test = test.drop(columns=['matchId'])\n",
        "del test\n",
        "gc.collect()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "5wqs5nImFtC2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7c71a5d-68f2-41f3-bd54-cf9ab1ad143c"
      },
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1934174, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "2hNzbRWRfdXV",
        "colab_type": "code",
        "outputId": "8c97dbaa-cc2b-41fb-86dd-7c80ba41bd29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_test = np.array(X_test)\n",
        "y_pred=model.predict(X_test, num_iteration=model.best_iteration)\n",
        "len(y_pred)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1934174"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "S5IkUwjt9EZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "debbc3c1-a5be-4b89-d17f-f486e8dbe02b"
      },
      "cell_type": "code",
      "source": [
        "del X_test\n",
        "gc.collect()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "435"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "4vzfm5x5fmbE",
        "colab_type": "code",
        "outputId": "a2401aa5-f291-473b-c120-d27bda6a72e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "# Insert ID and Predictions into dataframe\n",
        "df_sub = pd.DataFrame()\n",
        "df_test = pd.read_csv('test_V2.csv')\n",
        "df_test = reduce_mem_usage(df_test)\n",
        "df_sub['Id'] = df_test['Id']\n",
        "df_sub['winPlacePerc'] = y_pred\n",
        "print(df_sub['winPlacePerc'].describe())"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 413.18 MB\n",
            "Memory usage after optimization is: 121.74 MB\n",
            "Decreased by 70.5%\n",
            "count    1.934174e+06\n",
            "mean     4.731685e-01\n",
            "std      3.041001e-01\n",
            "min     -1.077412e-01\n",
            "25%      2.024466e-01\n",
            "50%      4.593228e-01\n",
            "75%      7.431606e-01\n",
            "max      1.126404e+00\n",
            "Name: winPlacePerc, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g8MnrczAft3N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_sub = df_sub.merge(df_test[[\"Id\", \"matchId\", \"groupId\", \"maxPlace\", \"numGroups\"]], on=\"Id\", how=\"left\")\n",
        "df_sub_group = df_sub.groupby([\"matchId\", \"groupId\"]).first().reset_index()\n",
        "df_sub_group[\"rank\"] = df_sub_group.groupby([\"matchId\"])[\"winPlacePerc\"].rank()\n",
        "df_sub_group = df_sub_group.merge(\n",
        "    df_sub_group.groupby(\"matchId\")[\"rank\"].max().to_frame(\"max_rank\").reset_index(), \n",
        "    on=\"matchId\", how=\"left\")\n",
        "df_sub_group[\"adjusted_perc\"] = (df_sub_group[\"rank\"] - 1) / (df_sub_group[\"numGroups\"] - 1)\n",
        "df_sub = df_sub.merge(df_sub_group[[\"adjusted_perc\", \"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")\n",
        "df_sub[\"winPlacePerc\"] = df_sub[\"adjusted_perc\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZY-3-5cScPB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_sub.loc[df_sub.maxPlace == 0, \"winPlacePerc\"] = 0\n",
        "df_sub.loc[df_sub.maxPlace == 1, \"winPlacePerc\"] = 1\n",
        "subset = df_sub.loc[df_sub.maxPlace > 1]\n",
        "gap = 1.0 / (subset.maxPlace.values - 1)\n",
        "new_perc = np.around(subset.winPlacePerc.values / gap) * gap\n",
        "df_sub.loc[df_sub.maxPlace > 1, \"winPlacePerc\"] = new_perc\n",
        "# Edge case\n",
        "df_sub.loc[(df_sub.maxPlace > 1) & (df_sub.numGroups == 1), \"winPlacePerc\"] = 0\n",
        "assert df_sub[\"winPlacePerc\"].isnull().sum() == 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vmXa7fTsSVml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78c5eb2f-9bad-4d0e-ffc5-7d31ce8c5fc9"
      },
      "cell_type": "code",
      "source": [
        "df_sub.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1934174, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "V3DKeMIWSpV_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_sub[[\"Id\", \"winPlacePerc\"]].to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}