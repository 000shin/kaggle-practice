{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-KjiiDskL9RG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "id_VSpGq7kuF"
   },
   "outputs": [],
   "source": [
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "kc6HjrvCMnvo",
    "outputId": "d0b0ea78-52e7-45c4-bb6b-67ef8a0e62d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1017.83 MB\n",
      "Memory usage after optimization is: 322.31 MB\n",
      "Decreased by 68.3%\n",
      "Memory usage of dataframe is 413.18 MB\n",
      "Memory usage after optimization is: 121.74 MB\n",
      "Decreased by 70.5%\n",
      "(4446965, 29) (1934174, 28)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train_V2.csv')\n",
    "train = train[train['maxPlace']>1]\n",
    "train = train[train['winPlacePerc'].notnull()]\n",
    "test = pd.read_csv('test_V2.csv')\n",
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_b6uJWfrNBSj"
   },
   "outputs": [],
   "source": [
    "alldata = [train, test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2hcqhkeQjcR5"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "### 추가한 변수들\n",
    "* 매치에 참가한 사람 수 \n",
    "* 힐+부스트\n",
    "* 전체 움직인 거리 (걸어서, 차량 타고, 수영 통틀어)\n",
    "* 시간 대비 움직인 거리\n",
    "* 움직인 거리 대비 킬 수\n",
    "* 헤드샷 비율\n",
    "* 움직인 거리 대비 무기 획득 수\n",
    "* 헤드샷, 로드킬, 차량 파괴 모두 어느 정도의 실력 필요 -> skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vClOOwU-i98g"
   },
   "outputs": [],
   "source": [
    "for data in alldata :\n",
    "  data['playersJoined'] = data.groupby('matchId')['matchId'].transform('count')\n",
    "  data['healsAndBoosts'] = data['heals']+data['boosts']\n",
    "  data['totalDistance'] = data['walkDistance']+ 0.25* data['rideDistance'] + data['swimDistance']\n",
    "  data['distancePerDuration'] = data['totalDistance'] / data['matchDuration']\n",
    "  data['killsPerDistance'] = data['kills']/(data['totalDistance']+1) \n",
    "  data['killsPerDistance'].fillna(0, inplace=True)\n",
    "  data['headshotKillRate'] = data['headshotKills'] / data['kills']\n",
    "  data['killStreakRate'] = data['killStreaks']/data['kills']\n",
    "  data['weaponsPerDistance'] =data['weaponsAcquired']/(data['totalDistance']+1)\n",
    "  data['weaponsPerDistance'].fillna(0, inplace=True)\n",
    "  data['skill'] = data['headshotKills'] + data['roadKills'] + data['vehicleDestroys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "rYugJ4fxCoNF",
    "outputId": "f241454d-3f73-4c44-a9ae-336ea8773389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 483.47 MB\n",
      "Memory usage after optimization is: 356.24 MB\n",
      "Decreased by 26.3%\n",
      "Memory usage of dataframe is 191.84 MB\n",
      "Memory usage after optimization is: 136.50 MB\n",
      "Decreased by 28.8%\n"
     ]
    }
   ],
   "source": [
    "for data in alldata:\n",
    "  data['matchType'] = data['matchType'].map({\n",
    "      'crashfpp':1,\n",
    "      'crashtpp':2,\n",
    "      'duo':3,\n",
    "      'duo-fpp':4,\n",
    "      'flarefpp':5,\n",
    "      'flaretpp':6,\n",
    "      'normal-duo':7,\n",
    "      'normal-duo-fpp':8,\n",
    "      'normal-solo':9,\n",
    "      'normal-solo-fpp':10,\n",
    "      'normal-squad':11,\n",
    "      'normal-squad-fpp':12,\n",
    "      'solo':13,\n",
    "      'solo-fpp':14,\n",
    "      'squad':15,\n",
    "      'squad-fpp':16\n",
    "  })\n",
    "  data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPWS0JJMC3-D"
   },
   "outputs": [],
   "source": [
    "for data in alldata:\n",
    "  data.loc[(data['rankPoints']==-1), 'rankPoints'] = 0\n",
    "  data['points'] = data['rankPoints']+data['killPoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFrs0O6bBNUd"
   },
   "outputs": [],
   "source": [
    "for data in alldata:\n",
    "  match = data.groupby('matchId')\n",
    "  data['killsPerc'] = match['kills'].rank(pct=True).values\n",
    "  data['killPlacePerc'] = match['killPlace'].rank(pct=True).values\n",
    "  data['walkDistancePerc'] = match['walkDistance'].rank(pct=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rPy2P7qLyPbm",
    "outputId": "c0199016-f566-4e7f-e5ae-a36934c770a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4446965, 42) (1934174, 41)\n"
     ]
    }
   ],
   "source": [
    "for data in alldata:\n",
    "  data[data==np.Inf] = np.NaN\n",
    "  data[data==np.NINF] = np.NaN\n",
    "  data.fillna(0, inplace=True)\n",
    "  \n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRAwlG47BORc"
   },
   "source": [
    "#### Group & Match\n",
    "* 개인 변수뿐 아니라 그룹/매치 변수가 중요하다.\n",
    "* 각 변수에 대해 그룹/매치 별 평균값 데이터 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6Cy2QKcDHGy"
   },
   "outputs": [],
   "source": [
    "features = list(train.columns)\n",
    "excl_col = ['Id','matchId','groupId','playersJoined','matchType','winPlacePerc']\n",
    "for c in excl_col:\n",
    "    features.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "CAdlC1hZB1Hi",
    "outputId": "7ec3228e-4c38-4ad4-aabf-d158dc287681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 460.39 MB\n",
      "Memory usage after optimization is: 170.46 MB\n",
      "Decreased by 63.0%\n",
      "Memory usage of dataframe is 587.59 MB\n",
      "Memory usage after optimization is: 170.09 MB\n",
      "Decreased by 71.1%\n",
      "Memory usage of dataframe is 1026.31 MB\n",
      "Memory usage after optimization is: 949.97 MB\n",
      "Decreased by 7.4%\n",
      "Memory usage of dataframe is 199.62 MB\n",
      "Memory usage after optimization is: 72.84 MB\n",
      "Decreased by 63.5%\n",
      "Memory usage of dataframe is 256.94 MB\n",
      "Memory usage after optimization is: 74.38 MB\n",
      "Decreased by 71.1%\n",
      "Memory usage of dataframe is 442.70 MB\n",
      "Memory usage after optimization is: 409.49 MB\n",
      "Decreased by 7.5%\n"
     ]
    }
   ],
   "source": [
    "def meandata(data):\n",
    "  meanData = data.groupby(['matchId','groupId'])[features].agg('mean')\n",
    "  meanData = reduce_mem_usage(meanData)\n",
    "  meanData = meanData.replace([np.inf, np.NINF,np.nan], 0)\n",
    "  meanDataRank = meanData.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "  meanDataRank = reduce_mem_usage(meanDataRank)\n",
    "  data = pd.merge(data, meanData.reset_index(), suffixes=[\"\", \"_mean\"], how='left', on=['matchId', 'groupId'])\n",
    "  del meanData\n",
    "  gc.collect()\n",
    "  data.drop([\"vehicleDestroys_mean\",\"rideDistance_mean\",\"roadKills_mean\",\"rankPoints_mean\"], axis=1, inplace=True)\n",
    "  data = pd.merge(data, meanDataRank, suffixes=[\"\", \"_meanRank\"], how='left', on=['matchId', 'groupId'])\n",
    "  del meanDataRank\n",
    "  gc.collect()\n",
    "  data.drop([\"numGroups_meanRank\",\"rankPoints_meanRank\"], axis=1, inplace=True)\n",
    "  data = reduce_mem_usage(data)\n",
    "  return data\n",
    "\n",
    "train = meandata(train)\n",
    "test = meandata(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "HcR2R1uCEtNw",
    "outputId": "be595b65-32a0-4295-9413-ac41ba1dd32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 46.39 MB\n",
      "Memory usage after optimization is: 32.86 MB\n",
      "Decreased by 29.2%\n",
      "Memory usage of dataframe is 20.28 MB\n",
      "Memory usage after optimization is: 14.37 MB\n",
      "Decreased by 29.2%\n"
     ]
    }
   ],
   "source": [
    "def groupsize(data):\n",
    "  groupSize = data.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n",
    "  groupSize = reduce_mem_usage(groupSize)\n",
    "  data = pd.merge(data, groupSize, how='left', on=['matchId', 'groupId'])\n",
    "  del groupSize\n",
    "  gc.collect()\n",
    "  return data\n",
    "\n",
    "train = groupsize(train)\n",
    "test = groupsize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHd4z7N55DyZ"
   },
   "outputs": [],
   "source": [
    "matchMeanFeatures = list(test.columns)[:41]\n",
    "excl_col = ['killPlacePerc','matchDuration','maxPlace','numGroups']\n",
    "for c in excl_col:\n",
    "  matchMeanFeatures.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "URzx74g1EtWK",
    "outputId": "8a14b105-42cd-4978-b275-ab6d8c5083c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 9.24 MB\n",
      "Memory usage after optimization is: 3.48 MB\n",
      "Decreased by 62.4%\n",
      "Memory usage of dataframe is 3.96 MB\n",
      "Memory usage after optimization is: 1.49 MB\n",
      "Decreased by 62.4%\n"
     ]
    }
   ],
   "source": [
    "def matchdata(data):\n",
    "  meanData = data.groupby(['matchId'])[matchMeanFeatures].agg('mean')\n",
    "  meanData = reduce_mem_usage(meanData)\n",
    "  meanData = meanData.replace([np.inf, np.NINF,np.nan], 0)\n",
    "  data = pd.merge(data, meanData.reset_index(), suffixes=[\"\", \"_matchMean\"], how='left', on=['matchId'])\n",
    "  del meanData\n",
    "  gc.collect()\n",
    "  return data\n",
    "\n",
    "train = matchdata(train)\n",
    "test = matchdata(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRtQVvA9wgHU"
   },
   "outputs": [],
   "source": [
    "#dropping features\n",
    "train.drop(['boosts','heals', 'headshotKills','roadKills','vehicleDestroys','killStreaks','rideDistance','swimDistance','matchDuration', 'maxPlace','numGroups','Id','groupId'], axis=1, inplace=True)\n",
    "test.drop(['boosts','heals', 'headshotKills','roadKills','vehicleDestroys','killStreaks','rideDistance','swimDistance','matchDuration', 'maxPlace','numGroups','Id','groupId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XihWhY761MJq",
    "outputId": "146459ba-5f7e-4fe7-d447-d3b06b74e4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4446965, 130) (1934174, 129)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wXJ4GANUw5Qn"
   },
   "outputs": [],
   "source": [
    "final_features = test.columns\n",
    "final_features = final_features.drop('matchId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gy3iPyOkOHwX"
   },
   "source": [
    "### Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-C71USRinadN"
   },
   "outputs": [],
   "source": [
    "def split_train_val(data, fraction):\n",
    "    matchIds = data['matchId'].unique().reshape([-1])\n",
    "    train_size = int(len(matchIds)*fraction)\n",
    "    \n",
    "    random_idx = np.random.RandomState(seed=2).permutation(len(matchIds))\n",
    "    train_matchIds = matchIds[random_idx[:train_size]]\n",
    "    val_matchIds = matchIds[random_idx[train_size:]]\n",
    "    \n",
    "    data_train = data.loc[data['matchId'].isin(train_matchIds)]\n",
    "    data_val = data.loc[data['matchId'].isin(val_matchIds)]\n",
    "    return data_train, data_val\n",
    "  \n",
    "X_train, X_val = split_train_val(train, 0.91)\n",
    "del train\n",
    "gc.collect()\n",
    "y_train = X_train['winPlacePerc']\n",
    "X_train = X_train.drop(columns=['matchId', 'winPlacePerc'])\n",
    "y_val = X_val['winPlacePerc']\n",
    "X_val = X_val.drop(columns=['matchId', 'winPlacePerc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xRAJLm3KoM0B",
    "outputId": "0bb9786d-9d2e-4293-8617-89a6433dc51c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "X_train, X_train2, y_train, y_train2 = train_test_split(X_train, y_train, test_size=0.1, shuffle=False)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_train2 = np.array(X_train2)\n",
    "y_train2 = np.array(y_train2)\n",
    "y_train = np.concatenate((y_train, y_train2), axis=0)\n",
    "del y_train2\n",
    "gc.collect()\n",
    "X_train = np.concatenate((X_train, X_train2), axis=0)\n",
    "del X_train2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bVpTsfxyomik",
    "outputId": "889d2210-f138-485a-80cf-217db7864dbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = lgb.Dataset(X_train, label=y_train)\n",
    "del X_train,y_train\n",
    "gc.collect()\n",
    "valid_set = lgb.Dataset(X_val, label=y_val)\n",
    "del X_val, y_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1615
    },
    "colab_type": "code",
    "id": "_tmpNU7UoxAG",
    "outputId": "8a4e193c-c3fb-4e4f-a6db-5da8e15b1b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.0428769\tvalid_1's l1: 0.0427829\n",
      "[200]\ttraining's l1: 0.0348968\tvalid_1's l1: 0.034997\n",
      "[300]\ttraining's l1: 0.0332657\tvalid_1's l1: 0.0335061\n",
      "[400]\ttraining's l1: 0.0321958\tvalid_1's l1: 0.0325481\n",
      "[500]\ttraining's l1: 0.0314616\tvalid_1's l1: 0.0319104\n",
      "[600]\ttraining's l1: 0.0308841\tvalid_1's l1: 0.0314321\n",
      "[700]\ttraining's l1: 0.0304251\tvalid_1's l1: 0.0310735\n",
      "[800]\ttraining's l1: 0.030031\tvalid_1's l1: 0.0307827\n",
      "[900]\ttraining's l1: 0.029702\tvalid_1's l1: 0.0305571\n",
      "[1000]\ttraining's l1: 0.0294084\tvalid_1's l1: 0.0303672\n",
      "[1100]\ttraining's l1: 0.0291466\tvalid_1's l1: 0.0301971\n",
      "[1200]\ttraining's l1: 0.0289103\tvalid_1's l1: 0.0300548\n",
      "[1300]\ttraining's l1: 0.028695\tvalid_1's l1: 0.0299334\n",
      "[1400]\ttraining's l1: 0.0284932\tvalid_1's l1: 0.029827\n",
      "[1500]\ttraining's l1: 0.0283092\tvalid_1's l1: 0.0297336\n",
      "[1600]\ttraining's l1: 0.0281407\tvalid_1's l1: 0.0296583\n",
      "[1700]\ttraining's l1: 0.0279822\tvalid_1's l1: 0.0295901\n",
      "[1800]\ttraining's l1: 0.0278309\tvalid_1's l1: 0.0295303\n",
      "[1900]\ttraining's l1: 0.0276854\tvalid_1's l1: 0.0294729\n",
      "[2000]\ttraining's l1: 0.0275484\tvalid_1's l1: 0.0294223\n",
      "[2100]\ttraining's l1: 0.0274184\tvalid_1's l1: 0.0293802\n",
      "[2200]\ttraining's l1: 0.0272918\tvalid_1's l1: 0.029338\n",
      "[2300]\ttraining's l1: 0.027173\tvalid_1's l1: 0.0293039\n",
      "[2400]\ttraining's l1: 0.0270513\tvalid_1's l1: 0.0292689\n",
      "[2500]\ttraining's l1: 0.0269353\tvalid_1's l1: 0.0292386\n",
      "[2600]\ttraining's l1: 0.0268258\tvalid_1's l1: 0.0292107\n",
      "[2700]\ttraining's l1: 0.0267227\tvalid_1's l1: 0.0291822\n",
      "[2800]\ttraining's l1: 0.0266207\tvalid_1's l1: 0.0291547\n",
      "[2900]\ttraining's l1: 0.0265162\tvalid_1's l1: 0.0291305\n",
      "[3000]\ttraining's l1: 0.0264131\tvalid_1's l1: 0.0291096\n",
      "[3100]\ttraining's l1: 0.0263136\tvalid_1's l1: 0.0290865\n",
      "[3200]\ttraining's l1: 0.0262151\tvalid_1's l1: 0.0290656\n",
      "[3300]\ttraining's l1: 0.0261202\tvalid_1's l1: 0.0290478\n",
      "[3400]\ttraining's l1: 0.0260291\tvalid_1's l1: 0.0290313\n",
      "[3500]\ttraining's l1: 0.0259367\tvalid_1's l1: 0.0290134\n",
      "[3600]\ttraining's l1: 0.0258475\tvalid_1's l1: 0.0289988\n",
      "[3700]\ttraining's l1: 0.0257555\tvalid_1's l1: 0.0289828\n",
      "[3800]\ttraining's l1: 0.025667\tvalid_1's l1: 0.0289663\n",
      "[3900]\ttraining's l1: 0.0255821\tvalid_1's l1: 0.0289542\n",
      "[4000]\ttraining's l1: 0.0254971\tvalid_1's l1: 0.0289403\n",
      "[4100]\ttraining's l1: 0.0254154\tvalid_1's l1: 0.028929\n",
      "[4200]\ttraining's l1: 0.0253355\tvalid_1's l1: 0.0289169\n",
      "[4300]\ttraining's l1: 0.0252572\tvalid_1's l1: 0.0289032\n",
      "[4400]\ttraining's l1: 0.0251767\tvalid_1's l1: 0.0288914\n",
      "[4500]\ttraining's l1: 0.0250991\tvalid_1's l1: 0.0288791\n",
      "[4600]\ttraining's l1: 0.0250209\tvalid_1's l1: 0.0288687\n",
      "[4700]\ttraining's l1: 0.0249445\tvalid_1's l1: 0.0288577\n",
      "[4800]\ttraining's l1: 0.0248676\tvalid_1's l1: 0.0288444\n",
      "[4900]\ttraining's l1: 0.0247934\tvalid_1's l1: 0.0288353\n",
      "[5000]\ttraining's l1: 0.024719\tvalid_1's l1: 0.0288254\n",
      "[5100]\ttraining's l1: 0.0246461\tvalid_1's l1: 0.0288165\n",
      "[5200]\ttraining's l1: 0.0245735\tvalid_1's l1: 0.0288086\n",
      "[5300]\ttraining's l1: 0.0245007\tvalid_1's l1: 0.0288022\n",
      "[5400]\ttraining's l1: 0.0244309\tvalid_1's l1: 0.0287933\n",
      "[5500]\ttraining's l1: 0.0243608\tvalid_1's l1: 0.0287854\n",
      "[5600]\ttraining's l1: 0.0242923\tvalid_1's l1: 0.0287778\n",
      "[5700]\ttraining's l1: 0.0242245\tvalid_1's l1: 0.0287704\n",
      "[5800]\ttraining's l1: 0.024158\tvalid_1's l1: 0.0287648\n",
      "[5900]\ttraining's l1: 0.0240921\tvalid_1's l1: 0.0287568\n",
      "[6000]\ttraining's l1: 0.0240258\tvalid_1's l1: 0.0287496\n",
      "[6100]\ttraining's l1: 0.0239596\tvalid_1's l1: 0.0287418\n",
      "[6200]\ttraining's l1: 0.0238952\tvalid_1's l1: 0.0287357\n",
      "[6300]\ttraining's l1: 0.0238287\tvalid_1's l1: 0.0287322\n",
      "[6400]\ttraining's l1: 0.0237665\tvalid_1's l1: 0.0287276\n",
      "[6500]\ttraining's l1: 0.0237025\tvalid_1's l1: 0.028724\n",
      "[6600]\ttraining's l1: 0.0236399\tvalid_1's l1: 0.0287192\n",
      "[6700]\ttraining's l1: 0.0235788\tvalid_1's l1: 0.0287136\n",
      "[6800]\ttraining's l1: 0.023519\tvalid_1's l1: 0.0287071\n",
      "[6900]\ttraining's l1: 0.0234576\tvalid_1's l1: 0.0287037\n",
      "[7000]\ttraining's l1: 0.0233949\tvalid_1's l1: 0.0286975\n",
      "[7100]\ttraining's l1: 0.0233364\tvalid_1's l1: 0.0286925\n",
      "[7200]\ttraining's l1: 0.0232773\tvalid_1's l1: 0.0286874\n",
      "[7300]\ttraining's l1: 0.0232184\tvalid_1's l1: 0.0286832\n",
      "[7400]\ttraining's l1: 0.0231607\tvalid_1's l1: 0.02868\n",
      "[7500]\ttraining's l1: 0.0231014\tvalid_1's l1: 0.028676\n",
      "[7600]\ttraining's l1: 0.0230444\tvalid_1's l1: 0.0286712\n",
      "[7700]\ttraining's l1: 0.0229871\tvalid_1's l1: 0.0286669\n",
      "[7800]\ttraining's l1: 0.0229302\tvalid_1's l1: 0.0286612\n",
      "[7900]\ttraining's l1: 0.0228726\tvalid_1's l1: 0.0286587\n",
      "[8000]\ttraining's l1: 0.0228187\tvalid_1's l1: 0.0286549\n",
      "[8100]\ttraining's l1: 0.0227652\tvalid_1's l1: 0.02865\n",
      "[8200]\ttraining's l1: 0.0227097\tvalid_1's l1: 0.0286476\n",
      "[8300]\ttraining's l1: 0.0226577\tvalid_1's l1: 0.0286434\n",
      "[8400]\ttraining's l1: 0.0226005\tvalid_1's l1: 0.0286399\n",
      "[8500]\ttraining's l1: 0.0225452\tvalid_1's l1: 0.0286382\n",
      "[8600]\ttraining's l1: 0.0224921\tvalid_1's l1: 0.0286355\n",
      "[8700]\ttraining's l1: 0.0224379\tvalid_1's l1: 0.0286318\n",
      "[8800]\ttraining's l1: 0.0223851\tvalid_1's l1: 0.0286295\n",
      "[8900]\ttraining's l1: 0.0223332\tvalid_1's l1: 0.0286268\n",
      "[9000]\ttraining's l1: 0.022281\tvalid_1's l1: 0.0286239\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9000]\ttraining's l1: 0.022281\tvalid_1's l1: 0.0286239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "        \"objective\" : \"regression\", \n",
    "        \"metric\" : \"mae\", \n",
    "        \"num_leaves\" : 149, \n",
    "        \"learning_rate\" : 0.03, \n",
    "        \"bagging_fraction\" : 0.9,\n",
    "        \"bagging_seed\" : 0, \n",
    "        \"num_threads\" : 4,\n",
    "        \"colsample_bytree\" : 0.5,\n",
    "        'min_data_in_leaf':1900, \n",
    "        'min_split_gain':0.00011,\n",
    "        'lambda_l2':9\n",
    "}\n",
    "\n",
    "model = lgb.train(  params, \n",
    "                    train_set = train_set,\n",
    "                    num_boost_round=9000,\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=100, \n",
    "                    valid_sets=[train_set,valid_set]\n",
    "                  )\n",
    "  \n",
    "del train_set,valid_set\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fD_92bVZe9Fj",
    "outputId": "1e9d34ce-6102-4931-fc4f-47f7cc18661a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureImp = list(model.feature_importance())\n",
    "featureImp, features_label = zip(*sorted(zip(featureImp, final_features)))\n",
    "with open(\"FeatureImportance.txt\", \"w\") as text_file:\n",
    "    for i in range(len(featureImp)):\n",
    "        print(f\"{final_features[i]} =  {featureImp[i]}\", file=text_file)\n",
    "del featureImp,final_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "koNVGDFJA9HW",
    "outputId": "e1d9018f-933e-4297-b13e-375b92297fa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.drop(columns=['matchId'])\n",
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5wqs5nImFtC2",
    "outputId": "d7c71a5d-68f2-41f3-bd54-cf9ab1ad143c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934174, 128)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2hNzbRWRfdXV",
    "outputId": "8c97dbaa-cc2b-41fb-86dd-7c80ba41bd29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1934174"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(X_test)\n",
    "y_pred=model.predict(X_test, num_iteration=model.best_iteration)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S5IkUwjt9EZy",
    "outputId": "debbc3c1-a5be-4b89-d17f-f486e8dbe02b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "4vzfm5x5fmbE",
    "outputId": "a2401aa5-f291-473b-c120-d27bda6a72e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 413.18 MB\n",
      "Memory usage after optimization is: 121.74 MB\n",
      "Decreased by 70.5%\n",
      "count    1.934174e+06\n",
      "mean     4.731685e-01\n",
      "std      3.041001e-01\n",
      "min     -1.077412e-01\n",
      "25%      2.024466e-01\n",
      "50%      4.593228e-01\n",
      "75%      7.431606e-01\n",
      "max      1.126404e+00\n",
      "Name: winPlacePerc, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Insert ID and Predictions into dataframe\n",
    "df_sub = pd.DataFrame()\n",
    "df_test = pd.read_csv('test_V2.csv')\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "df_sub['Id'] = df_test['Id']\n",
    "df_sub['winPlacePerc'] = y_pred\n",
    "print(df_sub['winPlacePerc'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8MnrczAft3N"
   },
   "outputs": [],
   "source": [
    "df_sub = df_sub.merge(df_test[[\"Id\", \"matchId\", \"groupId\", \"maxPlace\", \"numGroups\"]], on=\"Id\", how=\"left\")\n",
    "df_sub_group = df_sub.groupby([\"matchId\", \"groupId\"]).first().reset_index()\n",
    "df_sub_group[\"rank\"] = df_sub_group.groupby([\"matchId\"])[\"winPlacePerc\"].rank()\n",
    "df_sub_group = df_sub_group.merge(\n",
    "    df_sub_group.groupby(\"matchId\")[\"rank\"].max().to_frame(\"max_rank\").reset_index(), \n",
    "    on=\"matchId\", how=\"left\")\n",
    "df_sub_group[\"adjusted_perc\"] = (df_sub_group[\"rank\"] - 1) / (df_sub_group[\"numGroups\"] - 1)\n",
    "df_sub = df_sub.merge(df_sub_group[[\"adjusted_perc\", \"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")\n",
    "df_sub[\"winPlacePerc\"] = df_sub[\"adjusted_perc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZY-3-5cScPB"
   },
   "outputs": [],
   "source": [
    "df_sub.loc[df_sub.maxPlace == 0, \"winPlacePerc\"] = 0\n",
    "df_sub.loc[df_sub.maxPlace == 1, \"winPlacePerc\"] = 1\n",
    "subset = df_sub.loc[df_sub.maxPlace > 1]\n",
    "gap = 1.0 / (subset.maxPlace.values - 1)\n",
    "new_perc = np.around(subset.winPlacePerc.values / gap) * gap\n",
    "df_sub.loc[df_sub.maxPlace > 1, \"winPlacePerc\"] = new_perc\n",
    "# Edge case\n",
    "df_sub.loc[(df_sub.maxPlace > 1) & (df_sub.numGroups == 1), \"winPlacePerc\"] = 0\n",
    "assert df_sub[\"winPlacePerc\"].isnull().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vmXa7fTsSVml",
    "outputId": "78c5eb2f-9bad-4d0e-ffc5-7d31ce8c5fc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934174, 7)"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3DKeMIWSpV_"
   },
   "outputs": [],
   "source": [
    "df_sub[[\"Id\", \"winPlacePerc\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제출 결과 : 0.02337"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pubg",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
