{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "* 데이터가 익명화되어 숫자들로 치환되어 있음 (따로 전처리 과정 불필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "del train['target'], train['id']\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_id = test['id']\n",
    "del test['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처 엔지니어링\n",
    "어떤 변수인지 드러난 정보가 없기 때문에 방향성 찾기 어려움... 탐색적 데이터 분석 과정 참고\n",
    "1. 운전자별 결측값의 개수를 나타내는 missing 변수 (운전을 시작한 시기에 대한 정보나 데이터 출처에 대한 간접적 정보 표현 가능)\n",
    "2. 이진 변수들의 총합 (변수간의 상호작용으로 얻을 수 있는 고차원 정보 추출)\n",
    "3. Target Encoding 파생 변수 (단일 변수의 고유값별 타겟 변수의 평균값을 새로운 변수로 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 결측값을 의미하는 “-1”의 개수 세기\n",
    "train['missing'] = (train==-1).sum(axis=1).astype(float)\n",
    "test['missing'] = (test==-1).sum(axis=1).astype(float)\n",
    "\n",
    "#2. 이진 변수의 합\n",
    "bin_features = [c for c in train.columns if 'bin' in c]\n",
    "train['bin_sum'] = train[bin_features].sum(axis=1)\n",
    "test['bin_sum'] = test[bin_features].sum(axis=1)\n",
    "\n",
    "#3. Target Encoding은 data leaking 방지하기 위해 교차검증과정에서 함!\n",
    "\n",
    "features = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_12_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_11_cat', 'ps_ind_01', 'ps_ind_03', 'ps_ind_15', 'ps_car_11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습\n",
    "* LightGBM\n",
    "* 5-Fold StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 설정\n",
    "num_boost_round = 10000\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": 0.1,\n",
    "          \"num_leaves\": 15,\n",
    "          \"max_bin\": 256,\n",
    "          \"feature_fraction\": 0.6,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9,\n",
    "          \"seed\": 2018\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#지니 계수\n",
    "def gini(actual, pred):\n",
    "    assert (len(actual) == len(pred))\n",
    "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "    all = all[np.lexsort((all[:,2], -1 * all[:, 1]))]\n",
    "    totalLosses = all[:, 0].sum()\n",
    "    giniSum = all[:, 0].cumsum().sum() / totalLosses\n",
    "    giniSum -= (len(actual) +1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "def Gini(actual, pred):\n",
    "    return gini(actual,pred) / gini(actual, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yshin/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/yshin/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151606\tvalid_0's gini: 0.287939\n",
      "[200]\tvalid_0's binary_logloss: 0.151608\tvalid_0's gini: 0.287492\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's binary_logloss: 0.151591\tvalid_0's gini: 0.287982\n",
      "0.2879823369169921\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152424\tvalid_0's gini: 0.264158\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's binary_logloss: 0.1524\tvalid_0's gini: 0.265387\n",
      "0.2653866946078528\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152227\tvalid_0's gini: 0.276015\n",
      "[200]\tvalid_0's binary_logloss: 0.152186\tvalid_0's gini: 0.277444\n",
      "[300]\tvalid_0's binary_logloss: 0.152259\tvalid_0's gini: 0.274823\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's binary_logloss: 0.152175\tvalid_0's gini: 0.277855\n",
      "0.2778554545445486\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151903\tvalid_0's gini: 0.27917\n",
      "[200]\tvalid_0's binary_logloss: 0.151942\tvalid_0's gini: 0.2788\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's binary_logloss: 0.151889\tvalid_0's gini: 0.280343\n",
      "0.28034318566195054\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151729\tvalid_0's gini: 0.284918\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's binary_logloss: 0.151692\tvalid_0's gini: 0.286233\n",
      "0.28623330121679297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgbm\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "NFOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "kf = kfold.split(train, train_label)\n",
    "\n",
    "cv_train = np.zeros(len(train_label))\n",
    "cv_pred = np.zeros(len(test_id))    \n",
    "best_trees = []\n",
    "fold_scores = []\n",
    "def evalerror(preds,d):\n",
    "    labels = d.get_label()\n",
    "    return 'gini', Gini(labels,preds), True\n",
    "\n",
    "for i, (train_fold, validate) in enumerate(kf):\n",
    "    # 훈련/검증 데이터를 분리\n",
    "    X_train, X_validate, label_train, label_validate = train.iloc[train_fold, :], train.iloc[validate, :], train_label[train_fold], train_label[validate]\n",
    "    \n",
    "    # target encoding \n",
    "    for feature in features:\n",
    "        # 훈련 데이터에서 feature 고유값별 타겟 변수의 평균\n",
    "        map_dic = pd.DataFrame([X_train[feature], label_train]).T.groupby(feature).agg('mean')\n",
    "        map_dic = map_dic.to_dict()['target']\n",
    "        # 훈련/검증/테스트 데이터에 평균값을 매핑\n",
    "        X_train[feature + '_target_enc'] = X_train[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "        X_validate[feature + '_target_enc'] = X_validate[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "        test[feature + '_target_enc'] = test[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "    \n",
    "    dtrain = lgbm.Dataset(X_train, label_train)\n",
    "    dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "    # 훈련 데이터를 학습하고, evalerror() 함수를 통해 검증 데이터에 대한 정규화 Gini 계수 점수를 기준으로 최적의 트리 개수를 찾기\n",
    "    bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100, early_stopping_rounds=100)\n",
    "    best_trees.append(bst.best_iteration)\n",
    "    # 테스트 데이터에 대한 예측값을 cv_pred에 더하기\n",
    "    cv_pred += bst.predict(test, num_iteration=bst.best_iteration)\n",
    "    cv_train[validate] += bst.predict(X_validate)\n",
    "\n",
    "    # 검증 데이터에 대한 평가 점수를 출력\n",
    "    score = Gini(label_validate, cv_train[validate])\n",
    "    print(score)\n",
    "    fold_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score:\n",
      "0.2794294491958753\n",
      "[0.2879823369169921, 0.2653866946078528, 0.2778554545445486, 0.28034318566195054, 0.28623330121679297]\n",
      "[132, 82, 202, 145, 62] 124.6\n"
     ]
    }
   ],
   "source": [
    "cv_pred /= NFOLDS\n",
    "\n",
    "# 시드값별로 교차 검증 점수를 출력\n",
    "print(\"cv score:\")\n",
    "print(Gini(train_label, cv_train))\n",
    "print(fold_scores)\n",
    "print(best_trees, np.mean(best_trees))\n",
    "\n",
    "# 테스트 데이터에 대한 결과물을 저장\n",
    "pd.DataFrame({'id': test_id, 'target': cv_pred}).to_csv('lgbm_baseline.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
